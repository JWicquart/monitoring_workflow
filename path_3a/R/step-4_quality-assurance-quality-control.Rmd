---
title: "Path 3.A - Step 4 - Quality assurance and quality control"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: "cosmo"
    highlight: tango
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    toc_depth: 4
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

# Load data and packages

```{r base}

# 1. Required packages ----

library(tidyverse) # Core tidyverse packages
library(formattable)
library(DT)
library(leaflet)

# 2. Import data ----

synthetic_data <- read.csv2("./../data/03_synthetic-dataset.csv")

```

# Missing variables

```{r}

# 1. Missing variables* by dataset ----
# * variables present but only filled with NA

synthetic_data %>% 
  group_by(DatasetID) %>% 
  summarise_all(~(all(is.na(.)))) %>%
  pivot_longer(2:ncol(.), names_to = "Variable", values_to = "State") %>% 
  filter(State == TRUE) %>% 
  select(-State) %>% 
  group_by(DatasetID) %>% 
  mutate(Variable = paste(Variable, collapse = ", ")) %>% 
  unique(.) %>% # Remove duplicates
  arrange(DatasetID) %>% 
  formattable(.) %>% 
  as.datatable(., rownames = FALSE)

```

# Check duplicates

```{r}

# 1. Check for duplicated datasets integrated ----

synthetic_data %>% 
  # Remove variables that may have been completed differently 
  # in the data reformatting of the datasets
  select(-DatasetID, -Area, -Country, -Archipelago, 
         -Location, -Zone, -Method, -Observer) %>% 
  group_by_all() %>% 
  count() %>% 
  filter(n > 1) %>% 
  formattable(.) %>% 
  as.datatable(., rownames = FALSE)

```

# Check errors

## Quali. variables

```{r}

# 1. List of levels of factor of (some) qualitative variables by datasetID ----

# 1.1 Vector of variables names to list --

quali_var <- c("Area", "Country", "Archipelago", "Location", "Site", "Zone", "Method")

# 1.2 Make a for loop to list levels of factor for each variable --

for (i in 1:length(quali_var)) {
    
  list_i <- synthetic_data %>% 
    select(quali_var[i]) %>% 
    unique()
  
  print(list_i)
  
}

```

## Quanti. variables

```{r}

# 1. Histogram of (some) quantitative variables by datasetID ----

# 1.1 Vector of variables names to plot --

quanti_var <- c("Depth", "Year")

# 1.2 Make a for loop to plot each variable --

for (i in 1:length(quanti_var)) {
    
  plot_i <- ggplot() +
    #geom_histogram(data = synthetic_data %>% select(-DatasetID), 
    #               aes_string(x = quanti_var[i]), color = "lightgrey", fill = "lightgrey") +
    geom_histogram(data = synthetic_data, aes_string(x = quanti_var[i]), 
                   color = "#16a085", fill = "#2abb9b") +
    theme_bw() +
    labs(title = quanti_var[i]) +
    facet_wrap(~DatasetID, ncol = 3)
    
  print(plot_i)
    
}

```

## Metric variable

```{r}

# 1. First check of the total cover ----

# 1.1 Make the sum of percentage cover by sampling unit --

total_cover <- synthetic_data %>% 
  group_by(DatasetID, Area, Country, Archipelago, Location, Site, Zone, 
           Latitude, Longitude, Year, Date, Replicate, Observer, Depth) %>% 
  summarise(Total = sum(Cover))

# 1.2 Table of number of sampling units in the different categories, by DatasetID --

total_cover %>% 
  select(DatasetID, Total) %>% 
  group_by(DatasetID) %>% 
  summarise(Less_0 = length(which(Total < 0)), 
            Between_0_100 = length(which(Total > 0 & Total < 100)), 
            Equal_100 = length(which(Total == 100)), 
            More_100 = length(which(Total > 100)),
            Min = round(min(Total, na.rm = TRUE), 2),
            Max = round(max(Total, na.rm = TRUE), 2)) %>% 
  datatable(., rownames = FALSE,
            colnames = c("Dataset", "Cover < 0", 
                         "0 < Cover < 100", 
                         "Cover = 100", 
                         "Cover > 100", "Min", "Max")) %>% 
  formatStyle("Less_0", backgroundColor = "#e74c3c") %>% 
  formatStyle("Between_0_100", backgroundColor = "#f4b350") %>% 
  formatStyle("Equal_100", backgroundColor = "#16a085") %>% 
  formatStyle("More_100", backgroundColor = "#e74c3c")

# 1.3 Join the total cover with main data --

synthetic_data <- synthetic_data %>%
  left_join(., total_cover)

# 2. Adjust the cover (using the rule of three) ----

treshold <- 101 # Define the threshold

synthetic_data <- synthetic_data %>% 
  mutate(Cover = ifelse(Total > 100 & Total < treshold, (Cover*100)/Total, Cover))

# 3. First check of the total cover ----

# 3.1 Make the sum of percentage cover by sampling unit --

total_cover <- synthetic_data %>% 
  group_by(DatasetID, Area, Country, Archipelago, Location, Site, Zone, 
           Latitude, Longitude, Year, Date, Replicate, Observer, Depth) %>% 
  summarise(Total = sum(Cover))

# 3.2 Table of number of sampling units in the different categories, by DatasetID --

total_cover %>% 
  select(DatasetID, Total) %>% 
  group_by(DatasetID) %>% 
  summarise(Less_0 = length(which(Total < 0)), 
            Between_0_100 = length(which(Total > 0 & Total < 100)), 
            Equal_100 = length(which(Total == 100)), 
            More_100 = length(which(Total > 100)),
            Min = round(min(Total, na.rm = TRUE), 2),
            Max = round(max(Total, na.rm = TRUE), 2)) %>% 
  datatable(., rownames = FALSE,
            colnames = c("Dataset", "Cover < 0", 
                         "0 < Cover < 100", 
                         "Cover = 100", 
                         "Cover > 100", "Min", "Max")) %>% 
  formatStyle("Less_0", backgroundColor = "#e74c3c") %>% 
  formatStyle("Between_0_100", backgroundColor = "#f4b350") %>% 
  formatStyle("Equal_100", backgroundColor = "#16a085") %>% 
  formatStyle("More_100", backgroundColor = "#e74c3c")

# 3.3 Join the total cover with main data --

synthetic_data <- synthetic_data %>%
  select(-Total) %>% 
  left_join(., total_cover)

```

## Site coordinates

```{r fig.width=8}

# 1. Map of all sites locations ----

synthetic_data %>% 
  select(DatasetID, Longitude, Latitude) %>% 
  unique() %>% 
  leaflet(data = .) %>%
  addTiles() %>%
  addMarkers(~Longitude, ~Latitude, popup = ~as.character(DatasetID), 
             label = ~as.character(DatasetID))

```

# Export final file

```{r}

# 1. Remove rows with errors ----

synthetic_data_clean <- synthetic_data %>% 
  filter(Total > 0 & Total <= 100) %>% 
  filter(Cover > 0 & Cover <= 100)

# 2. Number and percentage of rows removed by dataset ----

left_join(synthetic_data %>% 
            group_by(DatasetID) %>% 
            count(name = "Before"),
          inner_join(synthetic_data, synthetic_data_clean) %>% 
            group_by(DatasetID) %>% 
            count(name = "After")) %>% 
  mutate(Removed_abs = Before - After,
         Removed_perc = (Removed_abs/Before)*100) %>% 
  formattable(., list(Removed = color_bar("#e74c3c"))) %>% 
  as.datatable(., rownames = FALSE, colnames = c("Dataset", "n rows before", 
                                                 "n rows after", "n rows removed", 
                                                 "n rows removed (%)"))

```

```{r}

# 1. Export final file ----

synthetic_data_clean %>% 
  select(DatasetID, Area, Country, Archipelago, 
         Location, Site, Zone, Latitude, Longitude, 
         Depth, Year, Date, Replicate, Method, Observer, 
         Category, Group, Family, Genus, Species, Cover) %>% # Re-order variables
  write.csv2(., "./../data/04_final-synthetic-dataset.csv", row.names = FALSE) # Export the data

```

# Reproducibility

```{r reprod}

# 1. Reproducibility ----

sessionInfo()

```

---
Jeremy WICQUART | jeremywicquart@gmail.com | `r format(Sys.time())`